{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1319bc46-6bc7-4c58-9830-792ff7363bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cead5aba-99cb-4ad1-a51b-f49a34268875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MyApp\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-avro_2.12:3.4.0\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafcf8be-c4ee-4f04-ba5e-3683aed07f2c",
   "metadata": {},
   "source": [
    "# create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "191ca349-e424-4b1b-b39b-ce8ee0ebf66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------------------------------------------------------------+\n",
      "|id |value                                                                   |\n",
      "+---+------------------------------------------------------------------------+\n",
      "|1  |{\"Zipcode\":85016,\"ZipCodeType\":\"STANDARD\",\"City\":\"Phoenix\",\"State\":\"AZ\"}|\n",
      "+---+------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    (1, \"\"\"{\"Zipcode\":85016,\"ZipCodeType\":\"STANDARD\",\"City\":\"Phoenix\",\"State\":\"AZ\"}\"\"\")\n",
    "]\n",
    "\n",
    "df_map = spark.createDataFrame(data, schema=(\"id\", \"value\"))\n",
    "df_map.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42f7ad47-5ae0-4497-ab73-93612556f803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "| id|    value|\n",
      "+---+---------+\n",
      "|  1|[1, 2, 3]|\n",
      "+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, '''[1, 2, 3]''')]\n",
    "df_arr=spark.createDataFrame(data,schema=(\"id\",\"value\"))\n",
    "df_arr.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "059d4536-d653-4b92-85a8-ebb3c4572412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------------------------------------------------------------+\n",
      "|id |value                                                                   |\n",
      "+---+------------------------------------------------------------------------+\n",
      "|1  |{\"Zipcode\":85016,\"ZipCodeType\":\"STANDARD\",\"City\":\"Phoenix\",\"State\":\"AZ\"}|\n",
      "+---+------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    (1, \"\"\"{\"Zipcode\":85016,\"ZipCodeType\":\"STANDARD\",\"City\":\"Phoenix\",\"State\":\"AZ\"}\"\"\")\n",
    "]\n",
    "\n",
    "df_struct = spark.createDataFrame(data, schema=(\"id\", \"value\"))\n",
    "df_struct.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9a07e3-a67d-4e36-978b-64dc34ac8228",
   "metadata": {},
   "source": [
    "# convert a json string columns to array/map/struct type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b4556a3-afae-464f-ae4c-8a64b8736815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- value: string (nullable = true)\n",
      " |-- map_column: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert to map type\n",
    "from pyspark.sql.types import MapType,StringType\n",
    "from pyspark.sql.functions import from_json\n",
    "\n",
    "schema=MapType(StringType(),StringType())\n",
    "df_map_new = df_map.withColumn('map_column',from_json(df_map.value,schema))\n",
    "df_map_new.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e28e8ea-e31d-4184-bb24-efb22893b77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+\n",
      "| id|               value|          map_column|\n",
      "+---+--------------------+--------------------+\n",
      "|  1|{\"Zipcode\":85016,...|{Zipcode -> 85016...|\n",
      "+---+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_map_new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "782fc809-2d5c-4e53-a9a8-8e7f60e61d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- value: string (nullable = true)\n",
      " |-- arr_column: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert to array type\n",
    "from pyspark.sql.types import ArrayType,IntegerType\n",
    "from pyspark.sql.functions import from_json\n",
    "\n",
    "schema=ArrayType(IntegerType())\n",
    "df_arr_new = df_arr.withColumn('arr_column',from_json(df_arr.value,schema))\n",
    "df_arr_new.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffa668a1-6743-4816-a826-ee41f65a0622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------+\n",
      "| id|    value|arr_column|\n",
      "+---+---------+----------+\n",
      "|  1|[1, 2, 3]| [1, 2, 3]|\n",
      "+---+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_arr_new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58b8dd06-4692-4c17-ba61-ae96e425284c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- value: string (nullable = true)\n",
      " |-- struct_column: struct (nullable = true)\n",
      " |    |-- Zipcode: string (nullable = true)\n",
      " |    |-- ZipCodeType: string (nullable = true)\n",
      " |    |-- City: string (nullable = true)\n",
      " |    |-- State: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert to struct type\n",
    "from pyspark.sql.types import StructType,StringType,StructField\n",
    "from pyspark.sql.functions import from_json\n",
    "\n",
    "schema=StructType([\n",
    "    StructField(\"Zipcode\",StringType()),\n",
    "    StructField(\"ZipCodeType\",StringType()),\n",
    "    StructField(\"City\",StringType()),\n",
    "    StructField(\"State\",StringType()),\n",
    "])\n",
    "df_struct_new = df_struct.withColumn('struct_column',from_json(df_struct.value,schema))\n",
    "df_struct_new.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2974866-acc7-4f60-81ba-7c2d5069badd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+\n",
      "| id|               value|       struct_column|\n",
      "+---+--------------------+--------------------+\n",
      "|  1|{\"Zipcode\":85016,...|{85016, STANDARD,...|\n",
      "+---+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_struct_new.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadaf165-7796-4481-b701-ee52bd43e38c",
   "metadata": {},
   "source": [
    "# convert array/map/struct type columns to string json columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3cf02074-1118-439f-8e7d-258434e3a89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- value: string (nullable = true)\n",
      " |-- map_column: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      " |-- to_json(map_column): string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_json\n",
    "df_map_new.select('*',to_json(df_map_new.map_column)).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9975689-9cb4-46f3-9f42-34898daf3603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- value: string (nullable = true)\n",
      " |-- arr_column: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      " |-- to_json(arr_column): string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_json\n",
    "df_arr_new.select('*',to_json(df_arr_new.arr_column)).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2ff9b1a-6aa0-4120-a2ef-347d5a1ffa2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- value: string (nullable = true)\n",
      " |-- struct_column: struct (nullable = true)\n",
      " |    |-- Zipcode: string (nullable = true)\n",
      " |    |-- ZipCodeType: string (nullable = true)\n",
      " |    |-- City: string (nullable = true)\n",
      " |    |-- State: string (nullable = true)\n",
      " |-- to_json(struct_column): string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_json\n",
    "df_struct_new.select('*',to_json(df_struct_new.struct_column)).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e1c743-c93c-44c4-b1b7-41028f1b1d1c",
   "metadata": {},
   "source": [
    "# schema of json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d4dfa8f-0767-426d-8fea-940dd17382a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column<'schema_of_json('{\"Zipcode\":85016,\"ZipCodeType\":\"STANDARD\",\"City\":\"Phoenix\",\"State\":\"AZ\"}')'>\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import schema_of_json,lit\n",
    "\n",
    "sample_json = df_struct.select(\"value\").first()[\"value\"]\n",
    "\n",
    "json_schema = schema_of_json(lit(sample_json))\n",
    "\n",
    "print(json_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3fedd579-f8b7-47d3-acf1-fe3675fc2aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------+\n",
      "|schema                                                                   |\n",
      "+-------------------------------------------------------------------------+\n",
      "|STRUCT<City: STRING, State: STRING, ZipCodeType: STRING, Zipcode: BIGINT>|\n",
      "+-------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_struct.select(json_schema.alias(\"schema\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6235f56-d0d9-4822-aaba-1308320ba6e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
