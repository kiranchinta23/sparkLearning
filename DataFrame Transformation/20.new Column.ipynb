{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d84d98e-c8bd-45a9-8712-d0ad72b70e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8ccd3e2-6f7e-4762-9e6a-f9f0a8691a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MyApp\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-avro_2.12:3.4.0\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4e07c9-11ae-4b3b-bc13-61d953a3c06b",
   "metadata": {},
   "source": [
    "# Create dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f21040af-8473-4dad-98d4-2071c463fd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "| 10|\n",
      "| 11|\n",
      "| 12|\n",
      "| 13|\n",
      "| 14|\n",
      "| 15|\n",
      "| 16|\n",
      "| 17|\n",
      "| 18|\n",
      "| 19|\n",
      "+---+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "spark_df=spark.range(100)\n",
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6f4ff1-93b0-42fc-b750-e82da8c3422a",
   "metadata": {},
   "source": [
    "# lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28ef2225-2ee5-4494-a5aa-8f84d3418148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+\n",
      "| id|new_constant_col|\n",
      "+---+----------------+\n",
      "|  0|               #|\n",
      "|  1|               #|\n",
      "|  2|               #|\n",
      "|  3|               #|\n",
      "|  4|               #|\n",
      "|  5|               #|\n",
      "|  6|               #|\n",
      "|  7|               #|\n",
      "|  8|               #|\n",
      "|  9|               #|\n",
      "| 10|               #|\n",
      "| 11|               #|\n",
      "| 12|               #|\n",
      "| 13|               #|\n",
      "| 14|               #|\n",
      "| 15|               #|\n",
      "| 16|               #|\n",
      "| 17|               #|\n",
      "| 18|               #|\n",
      "| 19|               #|\n",
      "+---+----------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "spark_df.withColumn('new_constant_col',lit('#')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1037882b-6796-42c4-99ba-bf8f6e98af48",
   "metadata": {},
   "source": [
    "# incremental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de043663-f602-4ff4-893e-02fb0032ec64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+\n",
      "| id|new_incremental_col|\n",
      "+---+-------------------+\n",
      "|  0|                  0|\n",
      "|  1|                  1|\n",
      "|  2|                  2|\n",
      "|  3|                  3|\n",
      "|  4|                  4|\n",
      "|  5|                  5|\n",
      "|  6|                  6|\n",
      "|  7|                  7|\n",
      "|  8|                  8|\n",
      "|  9|                  9|\n",
      "| 10|         8589934592|\n",
      "| 11|         8589934593|\n",
      "| 12|         8589934594|\n",
      "| 13|         8589934595|\n",
      "| 14|         8589934596|\n",
      "| 15|         8589934597|\n",
      "| 16|         8589934598|\n",
      "| 17|         8589934599|\n",
      "| 18|         8589934600|\n",
      "| 19|         8589934601|\n",
      "+---+-------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "spark_df.withColumn('new_incremental_col',monotonically_increasing_id()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b2450e-6039-4b7a-b672-10f24fdbd12d",
   "metadata": {},
   "source": [
    "# rand \n",
    "- uniform distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd7557b8-40ae-4cb9-b299-3a67efc336a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------------+\n",
      "|id |new_rand_col_uniform |\n",
      "+---+---------------------+\n",
      "|0  |0.9686366478115398   |\n",
      "|1  |0.7984991281171739   |\n",
      "|2  |0.8862838070400502   |\n",
      "|3  |0.7444178992815087   |\n",
      "|4  |0.7616329539462491   |\n",
      "|5  |0.9876985509634421   |\n",
      "|6  |0.8794945869410489   |\n",
      "|7  |0.3317138331639877   |\n",
      "|8  |0.733391019837264    |\n",
      "|9  |0.8853671530808603   |\n",
      "|10 |0.7578638408379902   |\n",
      "|11 |0.47380104858048366  |\n",
      "|12 |0.2693556476017388   |\n",
      "|13 |0.795767446006832    |\n",
      "|14 |0.0016005778123601155|\n",
      "|15 |0.9830440022131515   |\n",
      "|16 |0.8149321030335626   |\n",
      "|17 |0.24969660932336546  |\n",
      "|18 |0.2755471436014957   |\n",
      "|19 |0.6891097149590322   |\n",
      "+---+---------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import rand #-> uniform distribution\n",
    "spark_df.withColumn('new_rand_col_uniform',rand(70)).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b264aaa-440e-4c30-ac18-5b0216343726",
   "metadata": {},
   "source": [
    "# randn\n",
    "- normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3cd3ce4-3f99-4ed7-938d-6d4f163b0de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "|id |new_rand_col_uniform|\n",
      "+---+--------------------+\n",
      "|0  |0.5060974463351131  |\n",
      "|1  |0.3202289933218433  |\n",
      "|2  |0.7885168481267597  |\n",
      "|3  |-0.3496663257478285 |\n",
      "|4  |0.3344088607801314  |\n",
      "|5  |0.552164306637462   |\n",
      "|6  |-2.0825942895996192 |\n",
      "|7  |-0.4361165867484689 |\n",
      "|8  |1.5467497563004386  |\n",
      "|9  |1.4996010015864256  |\n",
      "|10 |1.6128589974640997  |\n",
      "|11 |-0.16386638151271365|\n",
      "|12 |-0.6594558232170213 |\n",
      "|13 |0.8456550639941086  |\n",
      "|14 |0.7301071180491999  |\n",
      "|15 |-0.5802783693518377 |\n",
      "|16 |-1.116359618647029  |\n",
      "|17 |0.9405736806453951  |\n",
      "|18 |-0.64483808120518   |\n",
      "|19 |0.2825687272582606  |\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import randn #-> normal distribution\n",
    "spark_df.withColumn('new_rand_col_uniform',randn(70)).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e213970-76da-4716-a93b-d8aab592609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cad2df-07cb-4aba-951c-bfc7d7e30b05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
